# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]            # ..., [ch_in_0 = 3 (RGB)]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2       # from, num_repeats = round(1 * depth_multiple), module, [ch_out_0 = ch_in_1 = 64 * 0.50, kernel_size = 3]
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4    # from, num_repeats = round(1 * depth_multiple), module, [ch_out_1 = ch_in_2 = 128 * 0.50, kernel_size = 3, stride = 2]
   [-1, 3, C3, [128]],                      # from, num_repeats = round(3 * depth_multiple), module, [ch_out_2 = ch_in_3 = 128 * 0.50]
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8    # ...
   [-1, 9, C3, [256]],                      # ...
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16   # ...
   [-1, 9, C3, [512]],                      # ...
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32  # ...
   [-1, 1, SPP, [1024, [5, 9, 13]]],        # ...,  [ch_out_8 = 1024 * 0.50, [Input feature maps are passed through three separate MaxPooling layers in parallel with unique kernels: 3x3, 9x9, 13x13]]
   [-1, 3, C3, [1024, False]],  # 9         # ...,  [..., residual connection in C3 Bottleneck = False]
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],    # ..., [size (output spatial size) = None , scale_factor (multiplier for spatial size) = 2, mode (the upsampling algorithm) = 'nearest']
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4  # [sum of [ch[-1] (last layer output) and ch[6] (7.th layer output, where 1. layer is Focus)]], ..., [concat dimension = 1]
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],    # Upsamples a given multi-channel 1D-, 2D-, or 3D-data -> The resolution of the input image is upsampled by the factor 2 (e.g. 32x32 -> 64x64)
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3  # [sum of [ch[-1] (last layer output) and ch[4] (5.th layer output, where 1. layer is Focus)]], ..., [concat dimension = 1]
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [num_classes, anchors]],  # Detect(P3, P4, P5)  # [Take the outputs of ch[17] (=128), ch[20] (=256), ch[23] (=512)], ..., [...]
  ]
